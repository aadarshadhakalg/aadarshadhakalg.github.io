<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title></title>
        <link>undefined</link>
        <description>undefined</description>
        <lastBuildDate>Sun, 04 Aug 2024 03:01:50 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>Joplin Pages Publisher</generator>
        <item>
            <title><![CDATA[Storage Locked / Cannot Use CEPH pool]]></title>
            <guid>8ef3d8f14d624ec1b2e204410bf573fd</guid>
            <pubDate>Sat, 03 Aug 2024 17:10:18 GMT</pubDate>
            <content:encoded><![CDATA[<p>cThis issue arises when you have a bad CRUSH rule or overall Ceph configuration set.</p>
<p>First of all, check the replication rule in the pool configuration.</p>
<p>In my case, I had set the <code>crush rule</code> or <code>replication</code> to <code>replicated_rule</code>, which by default disperses replicas across different hosts. I was running a single-node cluster, so the total number of hosts was 1. However, my number of replicas was set to 3 and the minimum number of replicas was set to 2. Since there was a single host, and the replication type was set to host, and the minimum replica was set to 2, the configuration failed.</p>
<p>For me, there were two solutions: either decrease the minimum replica to 1 to match the number of hosts, or, since I had two OSDs, change the replication type to OSD.</p>
<p>Both solutions work, but I preferred the second, so I set the replication type to OSD because some amount of redundancy is necessary to keep the data safe.</p>
<h2 id="creating-a-crush-rule">Creating a CRUSH Rule</h2>
<p>There are two types of replication:</p>
<ol>
<li>Across hosts</li>
<li>Across OSDs</li>
</ol>
<p>Step-by-step commands:</p>
<ol>
<li><code>ceph osd tree</code></li>
<li><code>ceph osd crush rule create-replicated replicated_osd default osd</code></li>
<li><code>ceph osd pool set prodpool crush_rule replicated_osd</code></li>
</ol>
<p>If you encounter any issues while using Ceph with Proxmox VE, or if you applied a wrong or bad configuration by mistake and are unable to log in to the Proxmox VE web interface, please fix the Ceph issue first using the command line by logging into an SSH session and then restarting Proxmox system services:</p>
<div><pre class="hljs"><code>systemctl restart pve-cluster.service
systemctl restart pvedaemon.service
systemctl restart pveproxy.service</code></pre></div>
<h3 id="cheatsheet">Cheatsheet</h3>
<ol>
<li>
<p>Dump details of all CRUSH rules:</p>
<div><pre class="hljs"><code>ceph osd crush rule dump</code></pre></div>
</li>
<li>
<p>List all CRUSH rules:</p>
<div><pre class="hljs"><code>ceph osd crush rule ls</code></pre></div>
</li>
<li>
<p>List OSD Tree:</p>
<div><pre class="hljs"><code>ceph osd tree</code></pre></div>
</li>
<li>
<p>Remove a CRUSH rule:</p>
<div><pre class="hljs"><code>ceph osd crush rule rm &lt;name&gt;</code></pre></div>
</li>
<li>
<p>Create a CRUSH rule:</p>
<div><pre class="hljs"><code>ceph osd crush rule create-replicated &lt;rule_name&gt; &lt;crush_tree_root&gt; &lt;<span class="hljs-built_in">type</span>&gt; [&lt;class&gt;]</code></pre></div>
<p>Example:</p>
<div><pre class="hljs"><code>ceph osd crush rule create-replicated replicated_osd default osd</code></pre></div>
</li>
<li>
<p>List all pools:</p>
<div><pre class="hljs"><code>ceph osd pool ls</code></pre></div>
</li>
<li>
<p>Show pool status:</p>
<div><pre class="hljs"><code>ceph osd pool stats</code></pre></div>
</li>
<li>
<p>Set CRUSH rule to the pool:</p>
<div><pre class="hljs"><code>ceph osd pool <span class="hljs-built_in">set</span> &lt;pool_name&gt; crush_rule &lt;crush_rule_name&gt;</code></pre></div>
<p>Example:</p>
<div><pre class="hljs"><code>ceph osd pool <span class="hljs-built_in">set</span> prodpool crush_rule replicated_osd</code></pre></div>
</li>
</ol>
]]></content:encoded>
        </item>
    </channel>
</rss>